{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c330b23-6984-4632-8d1e-fcd9ebf42953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_OREDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '3'\n",
    "import torch\n",
    "from torchvision.models import vgg16_bn\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "vgg16_bn = vgg16_bn(pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "238a18a8-8533-42f7-a081-50934bc79420",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vgg16_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bddfdb0f-b2db-4ae4-8499-51c14dea260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_output=[]\n",
    "def error_injection(name,num_error,start_index):\n",
    "    def hook(model,input):\n",
    "        start = start_index\n",
    "        end = start_index + num_error\n",
    "        #print(\"error_injection, input_shape:\",input[0][0][start:end].size())\n",
    "        input[0][0][start:end] = 0\n",
    "        print(\"shape :\",input[0][0].size())\n",
    "        feature_output.append(input[0][0].cpu())\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea5ca7d-03ce-4ce1-b874-b560166d28cc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.34 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_list = []\n",
    "num_error = 128\n",
    "error_index = 0\n",
    "for name,parameter in vgg16_bn.named_parameters():\n",
    "    if \"features.34.weight\" in name:\n",
    "        #print(name,\"size:\",parameter.size())\n",
    "        param_list.append(parameter)\n",
    "for name,layer in vgg16_bn.named_modules():\n",
    "    #print(name)\n",
    "    if \"features.34\" in name  and isinstance(layer, torch.nn.modules.conv.Conv2d):\n",
    "        print(name,layer) # target layer Conv5_1\n",
    "        handle = layer.register_forward_pre_hook(error_injection(name,num_error,error_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f170c0c-347b-4480-aefd-03bfeb5bb65f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eb84164-c323-4094-bd34-a586cd1740fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "image = Image.open('cat.jpg')\n",
    "transform = T.Compose([T.Resize((224,224)), T.ToTensor()])\n",
    "X = transform(image).unsqueeze(dim=0).to(device)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a6972c-eb8f-473f-83bc-a944406dab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "vgg16.to(device)\n",
    "for epoch in range(max_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        inputs,labels = data\n",
    "        inputs,labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = vgg16_bn(inputs)\n",
    "        # compute loss \n",
    "        loss = criterion(y_pred,labels)\n",
    "        #print(epoch,i, loss.item())\n",
    "        \n",
    "        if not torch.isfinite(loss):\n",
    "            print(\"WARNING: non-finite loss, ending training\")\n",
    "            exit(1)\n",
    "        else :\n",
    "            running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 30 == 29: \n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss/30)) \n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7550654e-b020-40d6-bb1b-0f6156662ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape : torch.Size([512, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "out = vgg16_bn(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4031957-2163-4daf-9ce9-f6816610354c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 14])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(feature_output[0][0].size())\n",
    "#a0 = save_output.outputs[0].cpu().detach().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb5819-7fb9-489b-921c-0a598c88dc00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdfe7940-2816-4e93-ad7d-618b48bb7523",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 th\n",
      "129 th\n",
      "130 th\n",
      "131 th\n",
      "132 th\n",
      "133 th\n",
      "134 th\n",
      "135 th\n",
      "136 th\n",
      "137 th\n",
      "138 th\n",
      "139 th\n",
      "140 th\n",
      "141 th\n",
      "142 th\n",
      "143 th\n",
      "144 th\n",
      "145 th\n",
      "146 th\n",
      "147 th\n",
      "148 th\n",
      "149 th\n",
      "150 th\n",
      "151 th\n",
      "152 th\n",
      "153 th\n",
      "154 th\n",
      "155 th\n",
      "156 th\n",
      "157 th\n",
      "158 th\n",
      "159 th\n",
      "160 th\n",
      "161 th\n",
      "162 th\n",
      "163 th\n",
      "164 th\n",
      "165 th\n",
      "166 th\n",
      "167 th\n",
      "168 th\n",
      "169 th\n",
      "170 th\n",
      "171 th\n",
      "172 th\n",
      "174 th\n",
      "175 th\n",
      "176 th\n",
      "177 th\n",
      "178 th\n",
      "179 th\n",
      "180 th\n",
      "181 th\n",
      "182 th\n",
      "183 th\n",
      "184 th\n",
      "185 th\n",
      "186 th\n",
      "187 th\n",
      "188 th\n",
      "189 th\n",
      "190 th\n",
      "191 th\n",
      "192 th\n",
      "193 th\n",
      "194 th\n",
      "195 th\n",
      "196 th\n",
      "197 th\n",
      "198 th\n",
      "199 th\n",
      "200 th\n",
      "201 th\n",
      "202 th\n",
      "203 th\n",
      "204 th\n",
      "205 th\n",
      "206 th\n",
      "207 th\n",
      "208 th\n",
      "209 th\n",
      "210 th\n",
      "211 th\n",
      "212 th\n",
      "213 th\n",
      "214 th\n",
      "215 th\n",
      "216 th\n",
      "217 th\n",
      "218 th\n",
      "219 th\n",
      "221 th\n",
      "222 th\n",
      "223 th\n",
      "224 th\n",
      "225 th\n",
      "226 th\n",
      "227 th\n",
      "228 th\n",
      "229 th\n",
      "230 th\n",
      "231 th\n",
      "232 th\n",
      "233 th\n",
      "234 th\n",
      "235 th\n",
      "236 th\n",
      "237 th\n",
      "238 th\n",
      "239 th\n",
      "240 th\n",
      "241 th\n",
      "242 th\n",
      "243 th\n",
      "244 th\n",
      "245 th\n",
      "246 th\n",
      "247 th\n",
      "248 th\n",
      "249 th\n",
      "250 th\n",
      "251 th\n",
      "252 th\n",
      "253 th\n",
      "254 th\n",
      "255 th\n",
      "256 th\n",
      "257 th\n",
      "258 th\n",
      "259 th\n",
      "260 th\n",
      "261 th\n",
      "262 th\n",
      "263 th\n",
      "264 th\n",
      "265 th\n",
      "266 th\n",
      "267 th\n",
      "268 th\n",
      "269 th\n",
      "270 th\n",
      "271 th\n",
      "272 th\n",
      "273 th\n",
      "274 th\n",
      "275 th\n",
      "276 th\n",
      "277 th\n",
      "278 th\n",
      "279 th\n",
      "280 th\n",
      "281 th\n",
      "282 th\n",
      "283 th\n",
      "284 th\n",
      "285 th\n",
      "286 th\n",
      "287 th\n",
      "288 th\n",
      "289 th\n",
      "290 th\n",
      "291 th\n",
      "292 th\n",
      "293 th\n",
      "294 th\n",
      "295 th\n",
      "296 th\n",
      "297 th\n",
      "298 th\n",
      "299 th\n",
      "300 th\n",
      "301 th\n",
      "302 th\n",
      "303 th\n",
      "304 th\n",
      "305 th\n",
      "306 th\n",
      "307 th\n",
      "308 th\n",
      "309 th\n",
      "310 th\n",
      "311 th\n",
      "312 th\n",
      "313 th\n",
      "314 th\n",
      "315 th\n",
      "316 th\n",
      "317 th\n",
      "318 th\n",
      "319 th\n",
      "320 th\n",
      "321 th\n",
      "322 th\n",
      "323 th\n",
      "324 th\n",
      "325 th\n",
      "326 th\n",
      "327 th\n",
      "328 th\n",
      "329 th\n",
      "330 th\n",
      "331 th\n",
      "332 th\n",
      "333 th\n",
      "334 th\n",
      "335 th\n",
      "336 th\n",
      "337 th\n",
      "338 th\n",
      "339 th\n",
      "340 th\n",
      "341 th\n",
      "342 th\n",
      "343 th\n",
      "344 th\n",
      "345 th\n",
      "346 th\n",
      "347 th\n",
      "348 th\n",
      "349 th\n",
      "350 th\n",
      "351 th\n",
      "352 th\n",
      "353 th\n",
      "354 th\n",
      "355 th\n",
      "356 th\n",
      "357 th\n",
      "358 th\n",
      "359 th\n",
      "360 th\n",
      "361 th\n",
      "362 th\n",
      "363 th\n",
      "364 th\n",
      "365 th\n",
      "366 th\n",
      "367 th\n",
      "368 th\n",
      "369 th\n",
      "370 th\n",
      "371 th\n",
      "372 th\n",
      "373 th\n",
      "374 th\n",
      "375 th\n",
      "376 th\n",
      "377 th\n",
      "378 th\n",
      "379 th\n",
      "380 th\n",
      "381 th\n",
      "382 th\n",
      "384 th\n",
      "385 th\n",
      "386 th\n",
      "387 th\n",
      "388 th\n",
      "389 th\n",
      "391 th\n",
      "392 th\n",
      "393 th\n",
      "394 th\n",
      "395 th\n",
      "396 th\n",
      "397 th\n",
      "398 th\n",
      "399 th\n",
      "400 th\n",
      "401 th\n",
      "402 th\n",
      "403 th\n",
      "404 th\n",
      "405 th\n",
      "406 th\n",
      "407 th\n",
      "408 th\n",
      "409 th\n",
      "410 th\n",
      "411 th\n",
      "412 th\n",
      "413 th\n",
      "414 th\n",
      "415 th\n",
      "416 th\n",
      "417 th\n",
      "418 th\n",
      "419 th\n",
      "420 th\n",
      "421 th\n",
      "422 th\n",
      "423 th\n",
      "424 th\n",
      "425 th\n",
      "426 th\n",
      "427 th\n",
      "428 th\n",
      "429 th\n",
      "430 th\n",
      "431 th\n",
      "432 th\n",
      "433 th\n",
      "434 th\n",
      "435 th\n",
      "436 th\n",
      "437 th\n",
      "438 th\n",
      "439 th\n",
      "440 th\n",
      "441 th\n",
      "442 th\n",
      "443 th\n",
      "444 th\n",
      "445 th\n",
      "446 th\n",
      "447 th\n",
      "448 th\n",
      "449 th\n",
      "450 th\n",
      "451 th\n",
      "452 th\n",
      "453 th\n",
      "454 th\n",
      "455 th\n",
      "456 th\n",
      "457 th\n",
      "458 th\n",
      "459 th\n",
      "460 th\n",
      "461 th\n",
      "462 th\n",
      "463 th\n",
      "464 th\n",
      "465 th\n",
      "466 th\n",
      "468 th\n",
      "469 th\n",
      "470 th\n",
      "471 th\n",
      "472 th\n",
      "473 th\n",
      "474 th\n",
      "475 th\n",
      "476 th\n",
      "477 th\n",
      "478 th\n",
      "479 th\n",
      "480 th\n",
      "481 th\n",
      "482 th\n",
      "483 th\n",
      "484 th\n",
      "485 th\n",
      "486 th\n",
      "487 th\n",
      "488 th\n",
      "489 th\n",
      "490 th\n",
      "491 th\n",
      "492 th\n",
      "493 th\n",
      "494 th\n",
      "495 th\n",
      "496 th\n",
      "497 th\n",
      "498 th\n",
      "499 th\n",
      "500 th\n",
      "501 th\n",
      "502 th\n",
      "503 th\n",
      "504 th\n",
      "505 th\n",
      "506 th\n",
      "507 th\n",
      "508 th\n",
      "509 th\n",
      "510 th\n",
      "511 th\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transformss\n",
    "total = torch.tensor(np.zeros((14,14)))\n",
    "for i,item in enumerate(feature_output[0].squeeze()):\n",
    "    #print(item.shape)\n",
    "    if torch.count_nonzero(item) > 10:\n",
    "        print(i,\"th\")\n",
    "        total += item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4abf95ef-dd03-4456-870d-1fb6cd058cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe8489b0ed0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPOUlEQVR4nO3dXYyc1X3H8e9vZ1+8u7bx2uCAbVobxSUgRENkIQhVWgWiOgThXPQCFCK3iUQv0oZEkRIjLqJeVKqUKIKqEREiJKixQMWBBKEktUWCUKWEYl5KbeyACxQbFq/d9Rp71/a+/XsxY3W9sdf0nGeeXeX8PtJqd2bn7P/My2+fmWeeM39FBGb2+69jvidgZvVw2M0K4bCbFcJhNyuEw25WiM46i/UPdMfAqt7k8cNDS5PHajp5KADRyBs/bzLfbFHu+IzbPZRZO2fume9SRSN98lesPpQ89q39Exwenjpr8VrDPrCqly/9yw3J4x/7x5uSx3aO5d1540vS77zcwOTQZN74xnje+M5T6Vd+OvMfbGM8vXbHVN6ddmIgffL//vf3J4+99s/3n/N3fhpvVgiH3awQDrtZIbLCLmmjpN9K2idpS1WTMrPqJYddUgP4LvBp4ErgdklXVjUxM6tWzpb9WmBfRLwREePAo8CmaqZlZlXLCftqYOZ+/gOt884g6U5JOyXtHD2S+T6OmSXLCfvZ3nj+nTcnI+KBiNgQERv6B7ozyplZjpywHwAunXF6DfBu3nTMrF1ywv48sF7SOkndwG3Ak9VMy8yqlny4bERMSvob4F+BBvBQROyubGZmVqmsY+Mj4mfAzyqai5m1kY+gMyuEw25WiFqXuA4PLeWxe9OXqV74H8eSxzYGh5PHAsSpU8lj3/n85Vm1u95PX2550fNHsmpP9+W9XXpqeU/y2NGL8x6ey595K3lsjI5l1V58ycrksZc98dfJYwdH7jvn77xlNyuEw25WCIfdrBAOu1khHHazQjjsZoVw2M0K4bCbFcJhNyuEw25WCIfdrBAOu1khHHazQjjsZoWodYlrxyT0Dqf38G0cHEkv3pO3VHN66HDy2IHXJrJqH13XlTx2asmirNod41NZ4wevT3+Irdid10l1ajhveW+OjuGj6WPHLkovPEe8vGU3K4TDblYIh92sEA67WSFyurheKulXkvZI2i3prionZmbVytkbPwl8LSJelLQEeEHSjoh4taK5mVmFkrfsETEYES+2fj4G7OEsXVzNbGGo5H12SWuBa4DnzvK7O4E7Abp7l1VRzswSZO+gk7QY+DHwlYh4f/bvZ7Zs7upZnFvOzBJlhV1SF82gb42Ix6uZkpm1Q87eeAHfB/ZExHeqm5KZtUPOlv0G4PPAJyW93Pq6uaJ5mVnFcvqz/xugCudiZm3kI+jMCuGwmxWi1vXsueJketvkGElfXwygRvr/xb43RrJqn1y2In3shXnr+Dsm8taU9x1Mf6V3wZ6RrNrTE5PJYzt68z4HQJ2N5LHTvemf+TDX5ttbdrNCOOxmhXDYzQrhsJsVwmE3K4TDblYIh92sEA67WSEcdrNCOOxmhXDYzQrhsJsVwmE3K4TDblaIWpe4KoLGePryvRgbS6+duWQxJtLbLmvsZFZtZawyPXx13l3ck9n1uPv99MlrIq9ddI4Yz2uzTeRc74wPgJqjrLfsZoVw2M0K4bCbFcJhNytEFe2fGpJekvRUFRMys/aoYst+F80Orma2gOX2elsDfAZ4sJrpmFm75G7Z7wW+DpzzzXNJd0raKWnnxPhoZjkzS5XT2PEWYCgiXpjrcme0bO7uTy1nZplyGzveKukt4FGaDR5/VMmszKxyyWGPiLsjYk1ErAVuA34ZEXdUNjMzq5TfZzcrRCULYSLiGeCZKv6WmbWHt+xmhXDYzQpRf8vmvA7A6WVP5K0pnz6V3i6aC/Lecjy+Ov1/cv+BvBt87OKMtdVAdOSszZ6nBwt5LboB6ElvlR2N9lxvb9nNCuGwmxXCYTcrhMNuVgiH3awQDrtZIRx2s0I47GaFcNjNCuGwmxXCYTcrhMNuVgiH3awQDrtZIepd4hqg9I7N80qdXcljp5bktYs+uSJ9yeOJlVml6V+f17P56MHFyWNXP3YsqzbTGS2fG5ktvkfT24vHooyQdJz7seItu1khHHazQjjsZoVw2M0KkdvYcZmkbZL2Stoj6fqqJmZm1crdG38f8IuI+AtJ3UBfBXMyszZIDrukpcAngL8EiIhxYLyaaZlZ1XKexl8GHAJ+IOklSQ9K+p3PTHbLZrOFISfsncDHgPsj4hpgFNgy+0Ju2Wy2MOSE/QBwICKea53eRjP8ZrYA5bRsfg/YL+ny1lk3Aq9WMiszq1zu3vi/Bba29sS/AfxV/pTMrB2ywh4RLwMbqpmKmbWTj6AzK4TDblaI+tezT2as1c1o4avu9PXoAOpLPzhwsivvf+ofbE8/VmloQ09W7an/Gcgav/KdjPbDufdZT951zzI5mTxUpzIeL9PnbpHtLbtZIRx2s0I47GaFcNjNCuGwmxXCYTcrhMNuVgiH3awQDrtZIRx2s0I47GaFcNjNCuGwmxXCYTcrhMNuVoh617N3wHRP+v8X9fWm11be/7XpNemNzicW593M3SPp69lXPXs8q3bW5w8AU/3pa9JPfjivuXxPznr4kbze8OpPf6z2HG6k151jGb237GaFcNjNCuGwmxUit2XzVyXtlrRL0iOSFlU1MTOrVnLYJa0GvgxsiIirgAZwW1UTM7Nq5T6N7wR6JXXS7M3+bv6UzKwdcnq9vQN8G3gbGASORsT22Zdzy2azhSHnafwAsAlYB6wC+iXdMftybtlstjDkPI2/CXgzIg5FxATwOPDxaqZlZlXLCfvbwHWS+iSJZsvmPdVMy8yqlvOa/TlgG/Ai8J+tv/VARfMys4rltmz+JvDNiuZiZm3kI+jMCuGwmxWi1iWuU13i2Or0kn0rMtoHT02ljwXozFiaO53RthhojE6kjz2St1QzOtOXWwJMLF2ePPbkiryWzZD+eFk0kd5yGYDJ9Mdbz3B62Y45ynrLblYIh92sEA67WSEcdrNCOOxmhXDYzQrhsJsVwmE3K4TDblYIh92sEA67WSEcdrNCOOxmhXDYzQrhsJsVotb17NEJJ1coefyJdenrk08ty1uXPdmTPu+uE3nr2afWLU4e29ubdxePL+vOGj/dnX67jV2Uty06tSR97pq+MKv2ZG/64+342vQ22VNzXGVv2c0K4bCbFcJhNyvEecMu6SFJQ5J2zThvuaQdkl5vfc/4cDgzq8MH2bL/ENg467wtwNMRsR54unXazBaw84Y9Ip4FZn/e5Sbg4dbPDwOfrXZaZla11NfsH4qIQYDW95XnuuDMls2TY27ZbDZf2r6DbmbL5s4+t2w2my+pYT8o6RKA1veh6qZkZu2QGvYngc2tnzcDP61mOmbWLh/krbdHgF8Dl0s6IOmLwD8An5L0OvCp1mkzW8DOe+B0RNx+jl/dWPFczKyNfASdWSEcdrNC1LrEVdPQlfFW+/AV6S18+95LXzYI0D2aPr5v8FRW7eGP9CaPXbL3RFbtqcwlslOL0sc3xvOWBg+8djJ57Oiqnqzaoxenb0e7R9Lryi2bzcxhNyuEw25WCIfdrBAOu1khHHazQjjsZoVw2M0K4bCbFcJhNyuEw25WCIfdrBAOu1khHHazQjjsZoWodz37FPSMpK9Rnkpfzs6iI3Ms9P0ADn00vfiR9X1ZtVe+NJE+OPLWhHcNp68JB5jM+PjwjvGs0oxfkH6fTWW0mgaYzPjU9K7j6WM1x8cueMtuVgiH3awQDrtZIVJbNn9L0l5Jr0h6QtKyts7SzLKltmzeAVwVEVcDrwF3VzwvM6tYUsvmiNgeEZOtk78B1rRhbmZWoSpes38B+HkFf8fM2igr7JLuASaBrXNc5v/6s590f3az+ZIcdkmbgVuAz0Wc+8iNM/qzL3J/drP5knQEnaSNwDeAP42IsWqnZGbtkNqy+Z+AJcAOSS9L+l6b52lmmVJbNn+/DXMxszbyEXRmhXDYzQpR6xLXqR4Y+aP08UveTB+r6bylnkvfTG/ZPNGXt1wyGjljMwYDk8vyWhdP9aRf975Dk+e/0BymM5apdh/Pa/Hd/276dvTo+vS6MUeivWU3K4TDblYIh92sEA67WSEcdrNCOOxmhXDYzQrhsJsVwmE3K4TDblYIh92sEA67WSEcdrNCOOxmhXDYzQqhOT4Ytvpi0iHgv+e4yIXA4Zqm49qu/ftY+w8j4qKz/aLWsJ+PpJ0RscG1Xdu1q+en8WaFcNjNCrHQwv6Aa7u2a7fHgnrNbmbts9C27GbWJg67WSEWRNglbZT0W0n7JG2pse6lkn4laY+k3ZLuqqv2jDk0JL0k6ama6y6TtE3S3tb1v77G2l9t3d67JD0iaVGb6z0kaUjSrhnnLZe0Q9Lrre8DNdb+Vut2f0XSE5KWtaP2bPMedkkN4LvAp4ErgdslXVlT+UngaxFxBXAd8KUaa592F7Cn5poA9wG/iIiPAH9c1xwkrQa+DGyIiKuABnBbm8v+ENg467wtwNMRsR54unW6rto7gKsi4mrgNeDuNtU+w7yHHbgW2BcRb0TEOPAosKmOwhExGBEvtn4+RvMBv7qO2gCS1gCfAR6sq2ar7lLgE7QadEbEeESM1DiFTqBXUifQB7zbzmIR8SwwPOvsTcDDrZ8fBj5bV+2I2B4Rp9vd/AZY047asy2EsK8G9s84fYAaA3eapLXANcBzNZa9F/g6kNdr6P/vMuAQ8IPWS4gHJfXXUTgi3gG+DbwNDAJHI2J7HbVn+VBEDLbmNAisnIc5AHwB+HkdhRZC2M/WkKvW9wMlLQZ+DHwlIt6vqeYtwFBEvFBHvVk6gY8B90fENcAo7Xsae4bWa+NNwDpgFdAv6Y46ai80ku6h+VJyax31FkLYDwCXzji9hjY/rZtJUhfNoG+NiMfrqgvcANwq6S2aL10+KelHNdU+AByIiNPPYrbRDH8dbgLejIhDETEBPA58vKbaMx2UdAlA6/tQncUlbQZuAT4XNR3sshDC/jywXtI6Sd00d9Y8WUdhSaL5unVPRHynjpqnRcTdEbEmItbSvM6/jIhatnAR8R6wX9LlrbNuBF6tozbNp+/XSepr3f43Mj87KJ8ENrd+3gz8tK7CkjYC3wBujYixuuoSEfP+BdxMc6/kfwH31Fj3T2i+ZHgFeLn1dfM8XP8/A56queZHgZ2t6/4TYKDG2n8H7AV2Af8M9LS53iM09w9M0HxW80VgBc298K+3vi+vsfY+mvupTj/mvlfH7e7DZc0KsRCexptZDRx2s0I47GaFcNjNCuGwmxXCYTcrhMNuVoj/BVjdXUiGehHTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(total.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cffc3ebf-362c-437d-b6dc-cbee448a0f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total=None\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcd72ce-418d-4831-a0e6-9d13032660fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
