{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0 0.2.2\n",
      "TITAN RTX\n",
      "11.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_OREDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '3'\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dataset\n",
    "#from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "print(torch.__version__, torchvision.__version__)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.version.cuda)\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomness 제어 \n",
    "# https://hoya012.github.io/blog/reproducible_pytorch/\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20019 782\n"
     ]
    }
   ],
   "source": [
    "# dataset load\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "dataset_path = \"/media/2/Network/Imagenet_dup/\"\n",
    "retrain_model_path = \"/media/2/hwbae0326/F4F/models/\"\n",
    "# imagenet data load\n",
    "train_dataset = dataset.ImageFolder(root=dataset_path+\"train\",\n",
    "                                       transform=transform)\n",
    "val_dataset = dataset.ImageFolder(root=dataset_path+\"val\",\n",
    "                                       transform=transform)\n",
    "'''\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                        batch_size=64,\n",
    "                                        shuffle=False,\n",
    "                                        num_workers=4)\n",
    "'''\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                        batch_size=64,\n",
    "                                        shuffle=True,\n",
    "                                        num_workers=4) # for using subset\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                        batch_size=64,\n",
    "                                        shuffle=True,\n",
    "                                        num_workers=4)\n",
    "print(len(train_dataloader),len(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model 로드 \n",
    "vgg16_bn = torchvision.models.vgg16_bn(pretrained=True)\n",
    "\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    vgg16_bn = nn.DataParallel(vgg16_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' hard coding way to freeze weigth\\nct = 0\\nlayer_level = 1\\nback_layer = []\\nfor layer in vgg16_bn.children():\\n#    print(ct,layer)\\n    if layer_level is 1:\\n        for layer_1 in layer:    \\n            print(\"layer 1_\",ct,layer_1)\\n            for i,param in enumerate(layer_1.parameters()):\\n                if ct != 34:\\n                    param.requires_grad = False\\n                    #print(ct,\"layer false\")\\n                else :\\n                    if i == 0:\\n                        param.requires_grad = True\\n                        print(\"=====\",param.shape)\\n                        print(\"%d-%d_layer true\"%(ct,i))\\n                    else :\\n                        param.requires_grad = False\\n                        print(\"=====\",param.shape)\\n                        print(\"%d-%d_layer false\"%(ct,i))\\n                        \\n            ct +=1\\n    elif layer_level is 2:\\n    #    print(\"layer 2\",layer)  \\n        for param in layer_1.parameters():\\n            param.requires_grad = False\\n            #print(ct,\"layer false\")\\n        ct +=1\\n    elif layer_level is 3:\\n        for layer_1 in layer: \\n    #        print(\"layer 3\",layer_1) \\n            for param in layer_1.parameters():\\n                param.requires_grad = False\\n                #print(ct,\"layer false\")\\n            ct+=1\\n    layer_level +=1\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only conv5_1 is trainable\n",
    "''' hard coding way to freeze weigth\n",
    "ct = 0\n",
    "layer_level = 1\n",
    "back_layer = []\n",
    "for layer in vgg16_bn.children():\n",
    "#    print(ct,layer)\n",
    "    if layer_level is 1:\n",
    "        for layer_1 in layer:    \n",
    "            print(\"layer 1_\",ct,layer_1)\n",
    "            for i,param in enumerate(layer_1.parameters()):\n",
    "                if ct != 34:\n",
    "                    param.requires_grad = False\n",
    "                    #print(ct,\"layer false\")\n",
    "                else :\n",
    "                    if i == 0:\n",
    "                        param.requires_grad = True\n",
    "                        print(\"=====\",param.shape)\n",
    "                        print(\"%d-%d_layer true\"%(ct,i))\n",
    "                    else :\n",
    "                        param.requires_grad = False\n",
    "                        print(\"=====\",param.shape)\n",
    "                        print(\"%d-%d_layer false\"%(ct,i))\n",
    "                        \n",
    "            ct +=1\n",
    "    elif layer_level is 2:\n",
    "    #    print(\"layer 2\",layer)  \n",
    "        for param in layer_1.parameters():\n",
    "            param.requires_grad = False\n",
    "            #print(ct,\"layer false\")\n",
    "        ct +=1\n",
    "    elif layer_level is 3:\n",
    "        for layer_1 in layer: \n",
    "    #        print(\"layer 3\",layer_1) \n",
    "            for param in layer_1.parameters():\n",
    "                param.requires_grad = False\n",
    "                #print(ct,\"layer false\")\n",
    "            ct+=1\n",
    "    layer_level +=1\n",
    "'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=np.array([1,45,6,32,])\n",
    "tmp.argmax()\n",
    "tmp = np.append(tmp,77)\n",
    "model =None\n",
    "model =vgg16_bn\n",
    "tmp,type(model)\n",
    "torch.save(model.state_dict(), retrain_model_path+\"vgg16_bn_epoch_%d_state_dict.pt\"%(tmp[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.34 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_output=[] # extract 10 features from conv5_1 input\n",
    "def error_injection(name,num_error,start_index):\n",
    "    def hook(model,input):\n",
    "        start = start_index\n",
    "        end = start_index + num_error\n",
    "        input[0][:, start:end]=0\n",
    "        #print(\"shape :\",input[0][0].size())\n",
    "        if len(feature_output) < 10:\n",
    "            #print(\"error_injection, input_shape:\",input[0][0][start:end].size(),input[0][:, start:end].size())\n",
    "            feature_output.append(input[0][0].cpu())\n",
    "    return hook\n",
    "num_error = 128\n",
    "error_index = 0\n",
    "def hook_register(vgg16_bn,error_index,num_error):\n",
    "    param_list = []\n",
    "    for name,parameter in vgg16_bn.named_parameters():\n",
    "        if \"features.34.weight\" in name:\n",
    "        #print(name,\"size:\",parameter.size())\n",
    "            param_list.append(parameter)\n",
    "    for name,layer in vgg16_bn.named_modules():\n",
    "    #print(name)\n",
    "        if \"features.34\" in name  and isinstance(layer, torch.nn.modules.conv.Conv2d):\n",
    "            print(name,layer) # target layer Conv5_1\n",
    "            handle = layer.register_forward_pre_hook(error_injection(name,num_error,error_index))\n",
    "    return param_list\n",
    "param_list = hook_register(vgg16_bn,error_index,num_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation phasetraining\n",
    "def eval(model,dataloader,epoch):\n",
    "\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct =0\n",
    "    with torch.no_grad():\n",
    "        print(\"======eval start=======\")\n",
    "        for i, data in enumerate(dataloader):\n",
    "            inputs,labels = data\n",
    "            inputs,labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "            y_hat = model(inputs)\n",
    "            _, predicted = torch.max(y_hat.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            if(i%200 == 199):\n",
    "                print(\"step : {} / {}\".format(i + 1, int(len(val_dataset)/labels.size(0))))\n",
    "                #print(\".\",end=\"\")\n",
    "        print(\"\")\n",
    "    acc = 100*correct/total\n",
    "    print(\"%dth epoch acc of %s on imagenet : %.4f %%\" %(epoch, model.__class__.__name__,acc)) \n",
    "    print(\"======eval  end ======\")  \n",
    "    return acc\n",
    "#torch.save(vgg16_bn.state_dict(), retrain_model_path+\"test_vgg16_bn_state_dict.pt\")\n",
    "def model_copy(model):\n",
    "    return deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training\n",
    "# info\n",
    "def training(model,train_dataloader,optimizer,loss_fn,error_idx,num_error,max_epochs=30,subset=False):\n",
    "    print(\"before training\")\n",
    "    tmp_acc = eval(model,val_dataloader,0)\n",
    "    model.to(device)\n",
    "    info = [0.0,0.0] # high_acc, releated_epoch\n",
    "    top_acc_model= None\n",
    "    tolerance = 4\n",
    "    for epoch in range(max_epochs):\n",
    "        running_loss = 0.0\n",
    "        print(\"=====epoch %d start======\"%(epoch))\n",
    "        model.train()\n",
    "        cumulation= 0\n",
    "        for i, data in enumerate(train_dataloader):\n",
    "            inputs,labels = data\n",
    "            inputs,labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            y_pred = model(inputs)\n",
    "            # compute loss \n",
    "            loss = loss_fn(y_pred,labels)\n",
    "            #print(epoch,i, loss.item())\n",
    "            \n",
    "            if not torch.isfinite(loss):\n",
    "                print(\"WARNING: non-finite loss, ending training\")\n",
    "                exit(1)\n",
    "            else :\n",
    "                running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_sche.step()\n",
    "            if i % 100 == 99: \n",
    "                print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss/100)) \n",
    "                running_loss = 0.0\n",
    "            if subset is True and i>=400:\n",
    "                break\n",
    "            \n",
    "        tmp_acc = eval(model,val_dataloader,epoch)\n",
    "        if tmp_acc > info[0]:\n",
    "            info[0] = tmp_acc\n",
    "            info[1] = epoch\n",
    "            top_acc_model = model_copy(model)\n",
    "        elif cumulation < tolerance : # validation fail\n",
    "            cumulation +=1\n",
    "        else:\n",
    "            cumulation = 0\n",
    "            optimizer.param_groups[0]['lr'] *= 0.5\n",
    "            print(\"learning rate decreased to %f\"%(optimizer.param_groups[0]['lr']))\n",
    "        print(\"=====epoch %d end======\"%(epoch))\n",
    "    # save high_acc model\n",
    "    torch.save(top_acc_model, \n",
    "               retrain_model_path+\"%d~%d_pkt_err_vgg16_bn_acc_%.3f_epoch_%d_state_dict.pt\"\n",
    "               %(error_idx,error_idx+num_error,info[0],info[1]))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss(size_average = None).to(device)\n",
    "optimizer = torch.optim.SGD(param_list,lr=0.01,weight_decay=1e-4)\n",
    "lr_sche = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.99)\n",
    "max_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.34 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "**********error_idx :0, num error :128**********\n",
      "before training\n",
      "======eval start=======\n",
      "step : 100 / 781\n",
      "step : 200 / 781\n",
      "step : 300 / 781\n",
      "step : 400 / 781\n",
      "step : 500 / 781\n",
      "step : 600 / 781\n",
      "step : 700 / 781\n",
      "\n",
      "0th epoch acc of VGG on imagenet : 63.2920 %\n",
      "======eval  end ======\n",
      "=====epoch 0 start======\n",
      "[1,   100] loss: 0.901\n",
      "[1,   200] loss: 0.933\n",
      "[1,   300] loss: 0.887\n",
      "[1,   400] loss: 0.902\n",
      "======eval start=======\n",
      "step : 100 / 781\n",
      "step : 200 / 781\n",
      "step : 300 / 781\n",
      "step : 400 / 781\n",
      "step : 500 / 781\n",
      "step : 600 / 781\n",
      "step : 700 / 781\n",
      "\n",
      "0th epoch acc of VGG on imagenet : 69.9520 %\n",
      "======eval  end ======\n",
      "=====epoch 0 end======\n",
      "=====epoch 1 start======\n",
      "[2,   100] loss: 0.920\n",
      "[2,   200] loss: 0.906\n",
      "[2,   300] loss: 0.894\n",
      "[2,   400] loss: 0.905\n",
      "======eval start=======\n",
      "step : 100 / 781\n",
      "step : 200 / 781\n",
      "step : 300 / 781\n",
      "step : 400 / 781\n",
      "step : 500 / 781\n",
      "step : 600 / 781\n",
      "step : 700 / 781\n",
      "\n",
      "1th epoch acc of VGG on imagenet : 69.9380 %\n",
      "======eval  end ======\n",
      "=====epoch 1 end======\n",
      "=====epoch 2 start======\n",
      "[3,   100] loss: 0.913\n",
      "[3,   200] loss: 0.940\n",
      "[3,   300] loss: 0.892\n",
      "[3,   400] loss: 0.881\n",
      "======eval start=======\n",
      "step : 100 / 781\n",
      "step : 200 / 781\n",
      "step : 300 / 781\n",
      "step : 400 / 781\n",
      "step : 500 / 781\n",
      "step : 600 / 781\n",
      "step : 700 / 781\n",
      "\n",
      "2th epoch acc of VGG on imagenet : 69.8460 %\n",
      "======eval  end ======\n",
      "=====epoch 2 end======\n",
      "=====epoch 3 start======\n",
      "[4,   100] loss: 0.891\n",
      "[4,   200] loss: 0.901\n",
      "[4,   300] loss: 0.944\n",
      "[4,   400] loss: 0.886\n",
      "======eval start=======\n",
      "step : 100 / 781\n",
      "step : 200 / 781\n",
      "step : 300 / 781\n",
      "step : 400 / 781\n",
      "step : 500 / 781\n",
      "step : 600 / 781\n",
      "step : 700 / 781\n"
     ]
    }
   ],
   "source": [
    "num_error = 128\n",
    "for error_idx in range(0,512,num_error):\n",
    "    vgg16_bn = torchvision.models.vgg16_bn(pretrained=True)\n",
    "    param_list = hook_register(vgg16_bn,error_idx,num_error)\n",
    "    print(\"**********error_idx :%d, num error :%d**********\"%(error_idx, num_error))\n",
    "    training(vgg16_bn,train_dataloader,optimizer,loss_fn,error_idx,num_error, max_epochs,True) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"baseline evaluation\")\n",
    "vgg16_bn = torchvision.models.vgg16_bn(pretrained=True) # not error inserted\n",
    "# evaluation phase\n",
    "criterion = torch.nn.CrossEntropyLoss(size_average = None).to(device)\n",
    "\n",
    "vgg16_bn.cuda()\n",
    "vgg16_bn.eval()\n",
    "total = 0\n",
    "correct =0\n",
    "with torch.no_grad():\n",
    "    print(\"eval start\")\n",
    "    for i, data in enumerate(val_dataloader):\n",
    "        inputs,labels = data\n",
    "        inputs,labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        y_hat = vgg16_bn(inputs)\n",
    "        _, predicted = torch.max(y_hat.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        if(i%50 == 49):\n",
    "            print(\"step : {} / {}\".format(i + 1, int(len(val_dataset)/labels.size(0))))\n",
    "            #print(\".\",end=\"\")\n",
    "    print(\"\")\n",
    "print(\"acc of vgg16 not shuffle on imagenet : %.4f %%\" %(100*correct/total))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
