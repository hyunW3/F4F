{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "488943d1-e600-42c7-bb8a-cb9de2c715a6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from autoPyTorch import AutoNetClassification\n",
    "#https://github.com/automl/Auto-PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29e8bc7b-2d00-4aa3-b27d-d1c40ac342da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.model_selection \n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "X, y = sklearn.datasets.load_digits(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        sklearn.model_selection.train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b908743-9c18-457e-afb3-d49c5cf6aa26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 64), (1797,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a4b3ecf-e810-44f9-a93f-7ec9acc21067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp = np.reshape(X[2],(8,8))\n",
    "tmp.shape\n",
    "plt.imshow(tmp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7d1a5eb-ee7a-43a8-bdad-7719c56f82d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hwbae0326/.conda/envs/local_pytorch/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "23:15:57 [AutoNet] Start bohb\n",
      "23:15:57 DISPATCHER: started the 'discover_worker' thread\n",
      "23:15:57 DISPATCHER: started the 'job_runner' thread\n",
      "23:15:57 WORKER: start listening for jobs\n",
      "23:15:57 DISPATCHER: Pyro daemon running on 192.168.2.12:40661\n",
      "23:15:57 DISPATCHER: discovered new worker, hpbandster.run_0.worker.SALserver02.7141.-1140710462039040\n",
      "23:15:57 HBMASTER: adjusted queue size to (0, 1)\n",
      "23:15:57 DISPATCHER: A new worker triggered discover_worker\n",
      "23:15:57 HBMASTER: starting run at 1631196957.2364917\n",
      "23:15:57 WORKER: start processing job (0, 0, 0)\n",
      "23:15:57 Fit optimization pipeline\n",
      "23:15:57 [AutoNet] CV split 0 of 1\n",
      "23:15:57 Reduced initial budget 29.783942461013794 to cv budget 29.782406091690063 compensate for 0.0015363693237304688\n",
      "/home/hwbae0326/.conda/envs/local_pytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "/home/hwbae0326/.conda/envs/local_pytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "23:16:17 Finished train with budget 29.782406091690063: Preprocessing took 0s, Training took 19s, Wrap up took 0s. Total time consumption in s: 19\n",
      "23:16:17 [AutoNet] Done with current split!\n",
      "23:16:17 Aggregate the results across the splits\n",
      "23:16:17 Process 1 additional result(s)\n",
      "23:16:17 Training ['shapedresnet'] with budget 30.0 resulted in optimize-metric-loss: -94.5679012345679 took 20.318641424179077 seconds\n",
      "23:16:17 WORKER: registered result for job (0, 0, 0) with dispatcher\n",
      "23:16:17 WORKER: start processing job (0, 0, 1)\n",
      "23:16:17 Fit optimization pipeline\n",
      "23:16:17 [AutoNet] CV split 0 of 1\n",
      "23:16:17 Reduced initial budget 29.80154585838318 to cv budget 29.800217390060425 compensate for 0.0013284683227539062\n",
      "/home/hwbae0326/.conda/envs/local_pytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "/home/hwbae0326/.conda/envs/local_pytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "23:16:37 Finished train with budget 29.800217390060425: Preprocessing took 0s, Training took 19s, Wrap up took 0s. Total time consumption in s: 19\n",
      "23:16:37 [AutoNet] Done with current split!\n",
      "23:16:37 Aggregate the results across the splits\n",
      "23:16:37 Process 1 additional result(s)\n",
      "23:16:37 Training ['shapedresnet'] with budget 30.0 resulted in optimize-metric-loss: -90.8641975308642 took 20.408385515213013 seconds\n",
      "23:16:38 WORKER: registered result for job (0, 0, 1) with dispatcher\n",
      "23:16:38 WORKER: start processing job (0, 0, 2)\n",
      "23:16:38 Fit optimization pipeline\n",
      "23:16:38 [AutoNet] CV split 0 of 1\n",
      "23:16:38 Reduced initial budget 29.798532485961914 to cv budget 29.796977758407593 compensate for 0.001554727554321289\n",
      "/home/hwbae0326/.conda/envs/local_pytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "/home/hwbae0326/.conda/envs/local_pytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "23:16:58 Finished train with budget 29.796977758407593: Preprocessing took 0s, Training took 19s, Wrap up took 0s. Total time consumption in s: 19\n",
      "23:16:58 [AutoNet] Done with current split!\n",
      "23:16:58 Aggregate the results across the splits\n",
      "23:16:58 Process 1 additional result(s)\n",
      "23:16:58 Training ['shapedresnet'] with budget 30.0 resulted in optimize-metric-loss: -41.48148148148148 took 20.300315141677856 seconds\n",
      "23:16:58 WORKER: registered result for job (0, 0, 2) with dispatcher\n",
      "23:16:58 WORKER: start processing job (0, 0, 0)\n",
      "23:16:58 Fit optimization pipeline\n",
      "23:16:58 [AutoNet] CV split 0 of 1\n",
      "23:16:58 Reduced initial budget 89.7809784412384 to cv budget 89.77963590621948 compensate for 0.0013425350189208984\n",
      "/home/hwbae0326/.conda/envs/local_pytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "/home/hwbae0326/.conda/envs/local_pytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "23:18:18 Finished train with budget 89.77963590621948: Preprocessing took 0s, Training took 79s, Wrap up took 0s. Total time consumption in s: 79\n",
      "23:18:18 [AutoNet] Done with current split!\n",
      "23:18:18 Aggregate the results across the splits\n",
      "23:18:18 Process 1 additional result(s)\n",
      "23:18:18 Training ['shapedresnet'] with budget 90.0 resulted in optimize-metric-loss: -89.62962962962962 took 80.43408417701721 seconds\n",
      "23:18:18 WORKER: registered result for job (0, 0, 0) with dispatcher\n",
      "23:18:18 WORKER: start processing job (1, 0, 0)\n",
      "23:18:18 Fit optimization pipeline\n",
      "23:18:18 [AutoNet] CV split 0 of 1\n",
      "23:18:18 Reduced initial budget 89.81100296974182 to cv budget 89.81005358695984 compensate for 0.0009493827819824219\n",
      "/home/hwbae0326/.conda/envs/local_pytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "/home/hwbae0326/.conda/envs/local_pytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "23:19:38 Finished train with budget 89.81005358695984: Preprocessing took 0s, Training took 79s, Wrap up took 0s. Total time consumption in s: 79\n",
      "23:19:38 [AutoNet] Done with current split!\n",
      "23:19:38 Aggregate the results across the splits\n",
      "23:19:38 Process 1 additional result(s)\n",
      "23:19:39 Training ['shapedresnet'] with budget 90.0 resulted in optimize-metric-loss: -80.49382716049382 took 80.23578238487244 seconds\n",
      "23:19:39 WORKER: registered result for job (1, 0, 0) with dispatcher\n",
      "23:19:39 HBMASTER: Timelimit reached: wait for remaining 0 jobs\n",
      "23:19:39 DISPATCHER: Dispatcher shutting down\n",
      "23:19:39 DISPATCHER: shut down complete\n",
      "23:19:39 Start autonet with config:\n",
      "{'embeddings': ['none'], 'lr_scheduler': ['cosine_annealing'], 'networks': ['shapedresnet'], 'preprocessors': ['truncated_svd'], 'target_size_strategies': ['none'], 'over_sampling_methods': ['none'], 'under_sampling_methods': ['none'], 'batch_loss_computation_techniques': ['standard'], 'imputation_strategies': ['median'], 'initialization_methods': ['default'], 'loss_modules': ['cross_entropy_weighted'], 'normalization_strategies': ['standardize'], 'optimizer': ['sgd'], 'hyperparameter_search_space_updates': <autoPyTorch.utils.hyperparameter_search_space_update.HyperparameterSearchSpaceUpdates object at 0x7ff95e033fd0>, 'log_level': 'info', 'max_runtime': 300, 'min_budget': 30, 'max_budget': 90, 'validation_split': 0.3, 'result_logger_dir': '.', 'categorical_features': None, 'dataset_name': None, 'run_id': '0', 'task_id': -1, 'algorithm': 'bohb', 'portfolio_type': 'greedy', 'budget_type': 'time', 'eta': 3, 'min_workers': 1, 'working_dir': '.', 'network_interface_name': 'enp134s0f0', 'memory_limit_mb': 1000000, 'use_tensorboard_logger': False, 'run_worker_on_master_node': True, 'use_pynisher': True, 'refit_validation_split': 0.0, 'cross_validator': 'none', 'cross_validator_args': {}, 'min_budget_for_cv': 0, 'shuffle': True, 'final_activation': 'softmax', 'initializer': 'simple_initializer', 'additional_logs': [], 'optimize_metric': 'accuracy', 'additional_metrics': [], 'cuda': True, 'torch_num_threads': 1, 'full_eval_each_epoch': False, 'best_over_epochs': False, 'save_models': False, 'predict_model': None, 'early_stopping_patience': inf, 'early_stopping_reset_parameters': False, 'random_seed': 2256459473, 'num_iterations': inf, 'cv_splits': 1, 'increase_number_of_trained_datasets': False}\n",
      "23:19:39 Start Refitting\n",
      "23:19:39 [AutoNet] CV split 0 of 1\n",
      "23:19:39 Reduced initial budget 29.91926097869873 to cv budget 29.918379545211792 compensate for 0.0008814334869384766\n",
      "/home/hwbae0326/.conda/envs/local_pytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "/home/hwbae0326/.conda/envs/local_pytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "23:19:59 Finished train with budget 29.918379545211792: Preprocessing took 0s, Training took 19s, Wrap up took 0s. Total time consumption in s: 20\n",
      "23:19:59 [AutoNet] Done with current split!\n",
      "23:19:59 Aggregate the results across the splits\n",
      "23:19:59 Process 1 additional result(s)\n",
      "23:19:59 Done Refitting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.9\n"
     ]
    }
   ],
   "source": [
    "autoML = AutoNetClassification(\"tiny_cs\",\n",
    "                              log_level='info',\n",
    "                              max_runtime=300,\n",
    "                              min_budget=30,\n",
    "                              max_budget=90)\n",
    "autoML.fit(X_train, y_train, validation_split=0.3)\n",
    "y_pred = autoML.predict(X_test)\n",
    "print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5064d012-3c79-4f2b-ba7f-27b4837728df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
